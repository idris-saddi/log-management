% Internship Report - Log Management System
\documentclass[12pt,a4paper]{report}

\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{array}
\usepackage{longtable}
\usepackage{pgfgantt}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{float}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{fancyvrb}
\usepackage{verbatim}
\usepackage{pdflscape}
\usepackage{pdfpages}

% Geometry and spacing
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}
\onehalfspacing

% Hyperref setup
\hypersetup{colorlinks=true,linkcolor=blue,urlcolor=blue,citecolor=blue}

% Unicode support for verbatim
\usepackage[utf8]{inputenc}
\usepackage{newunicodechar}
\newunicodechar{âœ…}{[OK]}
\newunicodechar{âŒ}{[ERROR]}
\newunicodechar{ðŸ•’}{[CLOCK]}
\newunicodechar{ðŸ”Œ}{[PLUG]}
\newunicodechar{ðŸ“¦}{[PACKAGE]}
\newunicodechar{ðŸ”}{[REPEAT]}
\newunicodechar{ðŸ“Š}{[CHART]}
\newunicodechar{ðŸš¨}{[ALARM]}
\newunicodechar{âš }{[WARNING]}
\newunicodechar{ï¸}{}
\newunicodechar{ðŸ“ˆ}{[TREND]}
\newunicodechar{â±}{[TIMER]}
\newunicodechar{ðŸš€}{[ROCKET]}
\newunicodechar{ðŸ”}{[SEARCH]}
\newunicodechar{ðŸ”§}{[TOOL]}
\newunicodechar{â„¹}{[INFO]}
\newunicodechar{ðŸ“¢}{[ANNOUNCE]}
\newunicodechar{ðŸ”—}{[LINK]}
\newunicodechar{ðŸŽ‰}{[PARTY]}

% Title page
\begin{document}
\includepdf[pages=-]{PageDeGarde.docx.pdf}

% Acknowledgements
\chapter*{Acknowledgements}
\addcontentsline{toc}{chapter}{Acknowledgements}

I would like to express my sincere gratitude to \textbf{MedSirat} for providing me with the opportunity to undertake this enriching internship experience. Special thanks to my supervisor \textbf{Salma SEDDIK} for her invaluable guidance, technical expertise, and continuous support throughout this project.

I am deeply grateful to the entire MedSirat team for creating a collaborative and learning-oriented environment that enabled me to develop both technical and professional skills. Their trust in allowing me to work on the Siratify platform's critical infrastructure was instrumental to my growth.

I extend my appreciation to the \textbf{National Institute of Applied Sciences and Technology (INSAT)} and my academic advisors for their theoretical foundation and support, which provided the essential knowledge base for this practical implementation.

Finally, I acknowledge the open-source community behind the technologies used in this projectâ€”Spring Boot, Apache Kafka, Graylog, Docker, and OpenSearchâ€”whose robust tools made this comprehensive log management solution possible.

This internship has been a transformative experience that bridged academic learning with real-world application in a professional consulting environment.

\pagenumbering{roman}

% Abstract
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
This report presents the design and implementation of a \textbf{centralized log management system} for the Siratify platform's microservices environment. Siratify is an entrepreneurial ecosystem that connects entrepreneurs, investors, mentors, and support organizations. The primary objective was to \textbf{collect}, \textbf{aggregate}, \textbf{analyze}, and \textbf{monitor} application logs reliably and at scale for this multi-stakeholder platform. The solution is built with \textit{Spring Boot 3.5.3}, \textit{Apache Kafka}, and \textit{Graylog 6.3}, orchestrated via \textit{Docker Compose}. A dedicated \textit{log-service} consumes messages from the Kafka topic \texttt{logs} and forwards them to Graylog using \textit{GELF TCP}. The initialization script \texttt{graylog-init.sh} automates the creation of \textit{inputs}, \textit{streams}, \textit{dashboards}, and \textit{alerts} tailored for monitoring platform-specific metrics. The results show a \textbf{reduction in operational effort} and an \textbf{improvement in service observability} critical for maintaining Siratify's high-availability requirements.


\chapter*{Glossary and Acronyms}
\addcontentsline{toc}{chapter}{Glossary and Acronyms}
\begin{description}
  \item[Apache Kafka] Distributed event streaming platform for real-time data pipelines
  \item[Docker Compose] Tool for defining and running multi-container applications
  \item[GELF] Graylog Extended Log Format
  \item[Graylog] Open-source log management platform with search and alerting
  \item[IaC] Infrastructure as Code
  \item[MDC] Mapped Diagnostic Context - thread-local storage for log enrichment
  \item[Microservices] Architecture pattern using loosely coupled, deployable services
  \item[Observability] Understanding system state through logs, metrics, and traces
  \item[OpenSearch] Search and analytics engine for log data storage
  \item[SLI/SLO] Service Level Indicator/Objective
  \item[Spring Boot] Java framework for production-ready applications
  \item[SRE] Site Reliability Engineering
\end{description}


\tableofcontents
\listoffigures
\clearpage
\pagenumbering{arabic}


\clearpage
\chapter*{General Introduction}
\addcontentsline{toc}{chapter}{General Introduction}
Modern distributed systems, particularly multi-stakeholder platforms like Siratify, generate high volumes of heterogeneous logs across multiple services and infrastructure layers. Siratify, an entrepreneurial ecosystem platform that facilitates connections between entrepreneurs, investors, mentors, and support organizations, operates with complex user journeys and business-critical interactions that require comprehensive monitoring and observability.

Without centralization and structure, troubleshooting becomes slow and error-prone, potentially affecting user experience across the platform's diverse stakeholder base. This internship addresses these challenges by implementing a production-ready logging platform specifically designed for Siratify's requirements, enabling end-to-end visibility of user interactions, proactive alerting for business-critical flows, and operational insights with minimal manual configuration.

\chapter{Company Context and Objectives}
\section{Host Company Overview}
\textbf{MedSirat} is a leading consulting firm founded in 2007, operating across Africa and the MENA region with over 18 years of experience. Based in Tunis, Tunisia (12 Rue Ahmed Boukhari), the company supports governments, businesses, NGOs, and entrepreneurs through comprehensive business services.

\textbf{Industry:} Business Services and Consulting. \textbf{Core Services:} Strategic consulting, coaching, training, and venture development. \textbf{Mission:} To empower purpose-driven progress by delivering tailored solutions that address today's challenges and shape tomorrow's opportunities. \textbf{Geographic Reach:} Africa and MENA region. \textbf{Specialization Areas:} Strategy, HR \& Organizational Development, Finance \& Funding, Marketing \& Communication, AI \& Technology Integration, and Pedagogy \& Active Learning.

\section{Internship Context and Problem Statement}
The \textbf{Siratify platform} (http://siratify.com/), an entrepreneurial ecosystem that connects entrepreneurs, investors, mentors, and support organizations, utilizes a microservices architecture that required a robust, centralized approach to log collection and analysis. As a platform serving multiple stakeholder types with complex interactions, disparate logs across services were slowing incident resolution and hindering monitoring of critical business flows such as user registrations, investment matching, and mentoring connections.

The challenge was to implement a scalable logging pipeline for Siratify that ingests logs asynchronously, enriches them with business context, and renders them searchable and actionable in near real-time. This is particularly crucial for a platform handling sensitive data flows between entrepreneurs and investors, where system reliability and observability directly impact business outcomes.

\section{Objectives}
The internship objectives were as follows:
\begin{itemize}[leftmargin=1.2cm]
    \item Design a \textbf{centralized log ingestion architecture}.
    \item Implement a \textbf{reliable asynchronous transport} using Kafka.
    \item Integrate \textbf{GELF} (Graylog Extended Log Format) with MDC enrichment.
    \item Automate \textbf{Graylog provisioning} (inputs, streams, dashboards, alerts).
    \item Deliver a \textbf{containerized deployment} with reproducible environments.
\end{itemize}

\section{Project Plan (Gantt)}
The following Gantt chart summarizes the project plan.

\clearpage
\begin{landscape}
\begin{figure}[H]
\centering
\begin{ganttchart}[
    hgrid, vgrid,
    y unit chart=0.5cm,
    x unit = 0.3cm,
    time slot format=isodate,
    title/.append style={font=\tiny},
    bar/.append style={font=\tiny},
    group/.append style={font=\tiny},
    bar height=0.3,
    group height=0.3
]{2025-07-01}{2025-08-31}
    \gantttitlecalendar{year, month=name, week} \\
    % Phases
    \ganttgroup{Initiation}{2025-07-01}{2025-07-14} \\
    \ganttbar{Requirements \& Scoping}{2025-07-01}{2025-07-07} \\
    \ganttbar{Docker Environment}{2025-07-05}{2025-07-14} \\
    \ganttgroup{Implementation}{2025-07-15}{2025-08-18} \\
    \ganttbar{Spring Boot Services}{2025-07-15}{2025-07-28} \\
    \ganttbar{Kafka logs Topic}{2025-07-20}{2025-08-03} \\
    \ganttbar{Log Service (Consumer/GELF)}{2025-07-25}{2025-08-08} \\
    \ganttbar{Graylog Automation}{2025-08-05}{2025-08-18} \\
    \ganttgroup{Validation}{2025-08-19}{2025-08-31} \\
    \ganttbar{Integration Tests}{2025-08-19}{2025-08-28} \\
    \ganttbar{Dashboards \& Alerts Tuning}{2025-08-22}{2025-08-31}
\end{ganttchart}
\caption{Project Gantt chart for Siratify log management system implementation}
\end{figure}
\end{landscape}
\clearpage

\chapter{System Overview and Requirements}
\section{Functional Requirements}
\begin{itemize}[leftmargin=1.2cm]
  \item Collect logs from multiple services with minimal coupling.
  \item Support multiple log levels and structured fields.
  \item Provide search, dashboards, and alerts for operations.
  \item Automate provisioning to reduce manual setup.
\end{itemize}

\section{Non-Functional Requirements}
\begin{itemize}[leftmargin=1.2cm]
  \item Scalability via asynchronous message transport (Kafka).
  \item Resilience to partial outages (backpressure, retries).
  \item Security of transport and access control.
  \item Observability and maintainability for SRE workflows.
\end{itemize}

\chapter{Technology Selection and Methodology}
\section{Technology Stack Selection}
After evaluating log management solutions (ELK/OpenSearch, Graylog, Loki), \textbf{Graylog} was selected for its unified API enabling automated provisioning, built-in GELF support, and comprehensive stream routing capabilities suitable for Siratify's microservices architecture.

\section{Development Approach}
The project followed an iterative approach with weekly increments: requirements analysis, Docker environment setup, service implementation, Kafka integration, log-service development, and Graylog automation. Each phase delivered testable components validated through synthetic traffic and dashboard verification.

\section{Requirements Analysis}
Requirements were gathered focusing on Siratify's operational needs: centralized log search for user journey tracking, ERROR alerting for critical business flows, automated provisioning, and containerized deployment. Key priorities include log level distribution dashboards, MDC enrichment with user context, and service-specific monitoring capabilities.

\chapter{Architecture and Implementation}
\section{System Architecture Overview}

\begin{figure}[H]
\centering
\fbox{
\begin{minipage}{0.8\textwidth}
\centering
\vspace{2cm}
\textbf{SYSTEM ARCHITECTURE DIAGRAM}\\[0.5cm]
\textit{[Placeholder: Insert system architecture diagram showing:}\\
\textit{Services (service1, service2) â†’ Kafka Topic â†’ Log Service â†’ Graylog Stack]}\\[0.5cm]
\textit{Components: Microservices, Kafka Broker, Log Consumer, Graylog, OpenSearch, MongoDB}
\vspace{2cm}
\end{minipage}
}
\caption{System architecture showing the complete log management pipeline from microservices through Kafka to Graylog stack}
\label{fig:system-architecture}
\end{figure}

\textbf{Architecture Notes:} This diagram illustrates the decoupled architecture where microservices publish logs to Kafka topics, enabling asynchronous processing. The dedicated log-service acts as a consumer that enriches logs with MDC context before forwarding to Graylog via GELF TCP. The Graylog stack utilizes OpenSearch for log storage and MongoDB for configuration metadata.

\section{Log Flow Sequence}

\begin{figure}[H]
\centering
\fbox{
\begin{minipage}{0.8\textwidth}
\centering
\vspace{2cm}
\textbf{LOG FLOW SEQUENCE DIAGRAM}\\[0.5cm]
\textit{[Placeholder: Insert sequence diagram showing:}\\
\textit{1. Service generates log event}\\
\textit{2. JSON message sent to Kafka topic}\\
\textit{3. Log-service consumes and enriches}\\
\textit{4. GELF message forwarded to Graylog}\\
\textit{5. Storage in OpenSearch + Dashboard updates}
\vspace{2cm}
\end{minipage}
}
\caption{Sequence diagram detailing the end-to-end log processing flow from generation to visualization}
\label{fig:log-flow}
\end{figure}

\textbf{Flow Notes:} The sequence demonstrates the temporal relationship between components, highlighting the asynchronous nature of the pipeline. Each step includes error handling and retry mechanisms to ensure reliable log delivery even during component failures.

\section{Deployment Architecture}

\begin{figure}[H]
\centering
\fbox{
\begin{minipage}{0.8\textwidth}
\centering
\vspace{2cm}
\textbf{DEPLOYMENT TOPOLOGY DIAGRAM}\\[0.5cm]
\textit{[Placeholder: Insert deployment diagram showing:}\\
\textit{Docker containers, network topology, port mappings}\\
\textit{Volume mounts, service dependencies, initialization flow}
\vspace{2cm}
\end{minipage}
}
\caption{Docker-based deployment topology showing container orchestration and network configuration}
\label{fig:deployment}
\end{figure}

\textbf{Deployment Notes:} The containerized architecture enables reproducible environments across development, staging, and production. The Docker Compose orchestration manages service dependencies, persistent volumes for data storage, and automated initialization through the graylog-init container.

\section{Component Responsibilities}
\begin{itemize}[leftmargin=1.2cm]
  \item \textbf{service1/2}: Expose REST endpoints \texttt{/log} and publish events to Kafka
  \item \textbf{Kafka/Zookeeper}: Reliable asynchronous transport for log messages
  \item \textbf{log-service}: Kafka consumer with MDC enrichment and GELF TCP forwarding
  \item \textbf{Graylog}: Log ingestion, indexing, dashboards, alerting, and search capabilities
  \item \textbf{OpenSearch}: Scalable storage and search backend for log data
  \item \textbf{MongoDB}: Configuration storage for Graylog streams, dashboards, and alerts
\end{itemize}

\section{Design Rationale}
Kafka ensures asynchronous decoupling to mitigate backpressure and enable independent scaling. GELF provides structured transport with MDC support for rich contextual logging. Graylog's API-first approach enables complete automation of the logging infrastructure setup.

\section{Technology Stack}
\begin{itemize}[leftmargin=1.2cm]
  \item \textbf{Java 21} \& \textbf{Spring Boot 3.5.3}: Backend framework for microservices
  \item \textbf{Apache Kafka}: Distributed message streaming platform
  \item \textbf{Graylog 6.3}: Centralized log management platform
  \item \textbf{OpenSearch 2.x}: Search and analytics backend for log storage
  \item \textbf{MongoDB 6.0.5}: Metadata storage for Graylog configuration
  \item \textbf{Docker Compose}: Container orchestration for reproducible deployments
\end{itemize}

\section{Configuration Overview}
The system uses Docker Compose for orchestration with standardized configurations:
- Kafka bootstrap servers at \texttt{kafka:9092} with string serialization
- Log-service consumer group \texttt{log-consumers} with earliest offset reset
- GELF TCP input on port 12201 for structured log transport
- Service-specific streams with automated routing rules
- Persistent volumes for OpenSearch data and MongoDB configuration

\chapter{Implementation Results}
\section{Key Implementation Components}
The solution consists of:
\begin{itemize}[leftmargin=1.2cm]
  \item \textbf{REST endpoints}: Services expose \texttt{/log} endpoints accepting message and level parameters
  \item \textbf{Kafka integration}: JSON log events published to \texttt{logs} topic with string serialization
  \item \textbf{Log consumer}: Dedicated service consuming Kafka messages with MDC enrichment
  \item \textbf{GELF forwarding}: Structured logs sent to Graylog via TCP port 12201
  \item \textbf{Automated provisioning}: \texttt{graylog-init.sh} script creates inputs, streams, dashboards, and alerts
\end{itemize}

\section{Deployment and Configuration}
The system uses Docker Compose orchestration with:
\begin{itemize}[leftmargin=1.2cm]
  \item \textbf{Service discovery}: Container DNS resolution for inter-service communication
  \item \textbf{Persistent storage}: Volumes for OpenSearch data and MongoDB configuration
  \item \textbf{Network isolation}: Dedicated bridge network for secure internal communication
  \item \textbf{Automated initialization}: Init container waits for Graylog API and configures logging infrastructure
\end{itemize}

\section{Testing and Validation Results}
System validation demonstrated:
\begin{itemize}[leftmargin=1.2cm]
  \item \textbf{End-to-end log flow}: Messages successfully routed from service endpoints to Graylog dashboards
  \item \textbf{Automated alerting}: ERROR level logs trigger notifications within configured thresholds
  \item \textbf{Stream routing}: Service-specific logs correctly filtered into dedicated streams
  \item \textbf{Dashboard functionality}: Real-time visualization of log counts, level distribution, and timeline metrics
\end{itemize}

\chapter{Results and Analysis}
\section{System Performance}
The implemented solution achieved:
\begin{itemize}[leftmargin=1.2cm]
  \item Sub-second log ingestion latency from service to Graylog visibility
  \item Reliable message delivery through Kafka's asynchronous transport
  \item Automated infrastructure provisioning reducing manual setup time
  \item Scalable architecture supporting multiple concurrent services
\end{itemize}

\section{Operational Benefits}
Key improvements for Siratify platform operations:
\begin{itemize}[leftmargin=1.2cm]
  \item \textbf{Centralized visibility}: Unified log search across all microservices
  \item \textbf{Proactive monitoring}: Real-time dashboards and automated error alerting
  \item \textbf{Reduced MTTR}: Faster incident resolution through structured log analysis
  \item \textbf{Deployment automation}: Reproducible environments across development stages
\end{itemize}

\section{Limitations and Future Improvements}
Current limitations include single-node development configuration and basic schema structure. Future enhancements should consider:
\begin{itemize}[leftmargin=1.2cm]
  \item Multi-broker Kafka cluster for production fault tolerance
  \item TLS encryption for secure log transport in production environments
  \item Schema registry integration for event structure evolution
  \item Distributed tracing correlation for enhanced observability
\end{itemize}

\section{Kafka Consumer and GELF Forwarder}
The log-service consumes the \texttt{logs} topic and forwards to Graylog using a GELF TCP appender configured in Logback.

\begin{figure}[H]
\centering
\begin{Verbatim}[frame=single, fontsize=\small, xleftmargin=1cm, xrightmargin=1cm]
// See Appendix D for the full source
\end{Verbatim}
\caption{Excerpt: log-service Kafka consumer}
\label{fig:logconsumer}
\end{figure}

\section{Graylog Automation}
The \texttt{graylog-init.sh} script waits for the Graylog API, creates the global GELF TCP input, configures streams per service with routing rules, generates searches and dashboards with multiple widgets, and adds an ERROR-level alert with an HTTP notification.

\begin{figure}[H]
\centering
\begin{Verbatim}[frame=single, fontsize=\small, xleftmargin=1cm, xrightmargin=1cm]
1) Wait for Graylog API readiness
2) Create global GELF TCP input on port 12201
3) For each service: create stream, rules, search, dashboard
4) Add widgets (counts, level distribution, timeline, sources)
5) Create ERROR alert and attach HTTP notification
\end{Verbatim}
\caption{Automation script responsibilities}
\label{fig:initoverview}
\end{figure}

\chapter{Operational Considerations}
\section{Security and Compliance}
Production deployment requires TLS encryption for GELF transport, access control for Graylog UI, and data minimization policies to avoid logging sensitive information (PII). Regular security audits and credential rotation should be implemented.

\section{Scalability and Performance}
The architecture supports horizontal scaling through:
\begin{itemize}[leftmargin=1.2cm]
  \item Kafka partition increase for higher throughput
  \item Multiple log-service consumer instances 
  \item OpenSearch cluster expansion for storage scaling
  \item Load balancer integration for Graylog inputs
\end{itemize}

\section{Operational Procedures}
Key maintenance tasks include:
\begin{itemize}[leftmargin=1.2cm]
  \item Regular OpenSearch index lifecycle management
  \item MongoDB backup for Graylog configuration
  \item Log retention policy enforcement
  \item Dashboard and alert threshold tuning based on operational needs
\end{itemize}

\chapter*{General Conclusion}
\addcontentsline{toc}{chapter}{General Conclusion}
This internship consolidated skills in distributed architectures, messaging, observability, and containerized deployments while addressing real-world challenges for the Siratify entrepreneurial ecosystem platform. The delivered centralized log management solution provides a robust foundation for monitoring Siratify's microservices that facilitate connections between entrepreneurs, investors, mentors, and support organizations.

The implementation demonstrates how modern logging architecture can enhance platform reliability and user experience in multi-stakeholder environments. The automated provisioning reduces operational overhead while providing comprehensive visibility into system behavior through dashboards, alerts, and structured log search capabilities.

Future enhancements for Siratify include distributed tracing integration (OpenTelemetry), SSO integration for access control, and richer alert routing for business-critical platform events. The foundation established enables rapid extension to additional services and observability requirements as the platform scales.

\chapter*{Future Work}
\addcontentsline{toc}{chapter}{Future Work}
Planned improvements include:
\begin{itemize}[leftmargin=1.2cm]
  \item Secure-by-default TLS configuration across all services
  \item CI/CD integration for automated infrastructure changes
  \item Multi-environment configuration overlays (dev/staging/production)
  \item Schema registry implementation for event structure evolution
  \item Integration with distributed tracing systems for enhanced observability
\end{itemize}

\begin{thebibliography}{9}
\bibitem{graylog-doc} Graylog Documentation, \url{https://docs.graylog.org/}, accessed 09/23/2025.
\bibitem{kafka-doc} Apache Kafka Documentation, \url{https://kafka.apache.org/documentation/}, accessed 09/23/2025.
\bibitem{spring-doc} Spring Boot Reference, \url{https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/}, accessed 09/23/2025.
\bibitem{opensearch-doc} OpenSearch Documentation, \url{https://opensearch.org/docs/}, accessed 09/23/2025.
\bibitem{logback-gelf} logback-gelf, \url{https://github.com/mp911de/logstash-gelf}, accessed 09/23/2025.
\end{thebibliography}

\appendix
\chapter{docker-compose.yml}

This Docker Compose configuration orchestrates the complete log management system infrastructure, defining all services, networks, and dependencies required for centralized logging.

\section*{Infrastructure Components}

\begin{itemize}
\item \textbf{Graylog Stack:} MongoDB (metadata), OpenSearch (log storage), Graylog (web interface)
\item \textbf{Message Broker:} Kafka + Zookeeper for reliable log transport
\item \textbf{Application Services:} service1, service2 (log producers)
\item \textbf{Log Processing:} log-service (Kafka consumer â†’ GELF forwarder)
\item \textbf{Automation:} graylog-init (configuration setup)
\end{itemize}

\section*{Key Service Definitions}

\subsection*{Graylog Configuration}
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
graylog:
  image: graylog/graylog:6.3
  environment:
    GRAYLOG_ROOT_PASSWORD_SHA2: "8c6976e5...918" # admin:admin
    GRAYLOG_HTTP_EXTERNAL_URI: "http://localhost:9000/"
    GRAYLOG_ELASTICSEARCH_HOSTS: "http://opensearch:9200"
    GRAYLOG_MONGODB_URI: "mongodb://mongodb:27017/graylog"
  ports:
    - 9000:9000        # Web UI
    - 12201:12201/tcp  # GELF TCP input
  depends_on: [opensearch, mongo]
\end{Verbatim}

\subsection*{Kafka Message Broker}
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
kafka:
  image: wurstmeister/kafka
  environment:
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  ports:
    - "9092:9092"
  depends_on: [zookeeper]
\end{Verbatim}

\subsection*{Application Services}
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
service1:
  build: ./service1
  ports: ["8081:8081"]
  depends_on: [kafka, log-service]

log-service:
  build: ./log-service
  environment:
    - GRAYLOG_HOST=graylog
    - GRAYLOG_PORT=12201
  ports: ["8083:8083"]
  depends_on: [kafka, graylog]
\end{Verbatim}

\section*{Network and Persistence}
\begin{itemize}
\item \textbf{Network:} \texttt{graynet} bridge for service communication
\item \textbf{Volumes:} \texttt{mongo\_data}, \texttt{log\_data}, \texttt{graylog\_data} for persistence
\item \textbf{Port mapping:} 9000 (Graylog UI), 8081-8083 (services), 9092 (Kafka)
\end{itemize}

\section*{Startup Sequence}
\begin{enumerate}
\item Infrastructure: MongoDB, OpenSearch, Zookeeper
\item Message broker: Kafka
\item Log management: Graylog + graylog-init
\item Processing: log-service
\item Applications: service1, service2
\end{enumerate}

\textbf{Complete configuration available at:} \\
\url{https://github.com/idris-saddi/log-management/blob/master/docker-compose.yml}

\chapter{graylog-init.sh}

This script automates the complete Graylog configuration for the log management system. The script performs the following key operations:

\section*{Main Configuration Steps}

\begin{enumerate}
\item \textbf{Wait for Graylog API readiness}
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
until curl -s -u "$AUTH" "$GRAYLOG_URL/api/system/inputs" > /dev/null; do
  sleep 3
done
\end{Verbatim}

\item \textbf{Create GELF TCP Input} (port 12201)
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
GELF_PAYLOAD='{
  "title": "GELF TCP",
  "type": "org.graylog2.inputs.gelf.tcp.GELFTCPInput",
  "configuration": {"bind_address": "0.0.0.0", "port": 12201}
}'
curl -X POST "$GRAYLOG_URL/api/system/inputs" --data "$GELF_PAYLOAD"
\end{Verbatim}

\item \textbf{For each service, create:}
\begin{itemize}
\item Stream with routing rules
\item Dashboard with monitoring widgets
\item Alert conditions for ERROR level logs
\end{itemize}

\item \textbf{Stream creation example:}
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
STREAM_PAYLOAD='{
  "title": "Stream for service1",
  "description": "Auto-created stream for service1",
  "rules": [], "remove_matches_from_default_stream": false
}'
curl -X POST "$GRAYLOG_URL/api/streams" --data "$STREAM_PAYLOAD"
\end{Verbatim}

\item \textbf{Alert condition setup:}
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
ALERT_PAYLOAD='{
  "type": "message_count",
  "title": "High ERROR rate for service1",
  "parameters": {"threshold": 5, "time": 300, "threshold_type": "MORE"}
}'
curl -X POST "$GRAYLOG_URL/api/streams/$STREAM_ID/alerts/conditions"
\end{Verbatim}
\end{enumerate}

\section*{Key Features}
\begin{itemize}
\item Automated stream creation with service-specific routing
\item Dashboard generation with log count and error rate widgets  
\item Alert conditions for monitoring ERROR level messages
\item Comprehensive error handling and logging
\item Idempotent execution (can be run multiple times safely)
\end{itemize}

\textbf{Complete script available at:} \\
\url{https://github.com/idris-saddi/log-management/blob/master/graylog-init.sh}

\chapter{service1 LogController.java}

This REST controller provides HTTP endpoints for generating log messages that are sent to Kafka for centralized processing. It demonstrates how microservices can integrate with the log management system.

\section*{Key Functionality}

\begin{itemize}
\item \textbf{REST endpoints:} POST and GET \texttt{/log} for message generation
\item \textbf{Kafka integration:} Publishes structured log messages to the \texttt{logs} topic
\item \textbf{Level normalization:} Standardizes log levels (INFO, WARN, ERROR, DEBUG, TRACE)
\item \textbf{Service identification:} Automatically tags logs with service name
\end{itemize}

\section*{Core Implementation}

\begin{Verbatim}[frame=single, fontsize=\scriptsize]
@RestController
@RequestMapping("/log")
public class LogController {
    private final KafkaTemplate<String, String> kafkaTemplate;
    
    @Value("${spring.application.name}")
    private String applicationName;

    @PostMapping
    public ResponseEntity<?> postLog(
        @RequestParam(defaultValue = "Test log message") String message,
        @RequestParam(defaultValue = "INFO") String level) {
        
        Map<String, Object> log = new HashMap<>();
        log.put("timestamp", Instant.now().toString());
        log.put("message", message);
        log.put("level", normalizeLevel(level));
        log.put("service", applicationName);

        String logJson = objectMapper.writeValueAsString(log);
        kafkaTemplate.send("logs", logJson);
        return ResponseEntity.ok("Log sent to Kafka: " + logJson);
    }
}
\end{Verbatim}

\section*{Log Message Structure}
Generated messages follow this JSON format:
\begin{Verbatim}[frame=single, fontsize=\scriptsize]
{
  "timestamp": "2025-08-31T10:30:45.123Z",
  "message": "User authentication successful",
  "level": "INFO",
  "service": "service1"
}
\end{Verbatim}

\section*{Usage Examples}
\begin{itemize}
\item \texttt{POST /log?message=User\%20login\&level=INFO}
\item \texttt{GET /log?message=Database\%20error\&level=ERROR}
\end{itemize}

\textbf{Complete source code available at:} \\
\url{https://github.com/idris-saddi/log-management/blob/master/service1/src/main/java/com/idris/service1/LogController.java}

\chapter{log-service LogConsumer.java}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../log-service/src/main/java/com/idris/log_service/kafka/LogConsumer.java}

\chapter{logback-spring.xml (log-service)}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../log-service/src/main/resources/logback-spring.xml}

\chapter{service1 application.properties}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service1/src/main/resources/application.properties}

\chapter{service2 application.properties}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service2/src/main/resources/application.properties}

\chapter{service2 logback-spring.xml}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service2/src/main/resources/logback-spring.xml}

\chapter{log-service application.properties}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../log-service/src/main/resources/application.properties}

\chapter{service1 logback-spring.xml}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service1/src/main/resources/logback-spring.xml}

\end{document}
\addcontentsline{toc}{chapter}{General Conclusion}
This internship consolidated skills in distributed architectures, messaging, observability, and containerized deployments while addressing real-world challenges for the Siratify entrepreneurial ecosystem platform. The delivered centralized log management solution provides a robust foundation for monitoring Siratify's microservices that facilitate connections between entrepreneurs, investors, mentors, and support organizations.

The implementation demonstrates how modern logging architecture can enhance platform reliability and user experience in multi-stakeholder environments. The automated provisioning reduces operational overhead while providing comprehensive visibility into system behavior through dashboards, alerts, and structured log search capabilities.

Future enhancements for Siratify include distributed tracing integration (OpenTelemetry), SSO integration for access control, and richer alert routing for business-critical platform events. The foundation established enables rapid extension to additional services and observability requirements as the platform scales.

\chapter*{Future Work}
\addcontentsline{toc}{chapter}{Future Work}
Planned improvements include:
\begin{itemize}[leftmargin=1.2cm]
  \item Secure-by-default TLS configuration across all services
  \item CI/CD integration for automated infrastructure changes
  \item Multi-environment configuration overlays (dev/staging/production)
  \item Schema registry implementation for event structure evolution
  \item Integration with distributed tracing systems for enhanced observability
\end{itemize}

\section{Partitioning Strategy}
Choose Kafka partitions $P$ to satisfy consumer parallelism and throughput: $P \geq N_c$ (number of consumer instances). Measure processing time per message to compute required parallelism.

\chapter{Testing and Validation}
Integration tests validated end-to-end flow: HTTP ingestion at services, Kafka delivery, consumer processing, and visibility in Graylog. Additional tests included error-level alerts and dashboard widget correctness. Synthetic load tests assessed latency and throughput across components.

\section{Threats to Validity}
Internal validity threats include environment-specific behavior in Docker Compose vs. production. External validity threats involve generalizing performance results to different workloads. Mitigations include parameterized tests and workload modeling.

\chapter{Troubleshooting and Operations}
Common issues involve container startup order, Kafka connectivity, and Graylog API availability. The init script includes retries and readiness checks. Operators can use container logs and Graylog search to diagnose issues quickly.

\chapter{Results and Discussion}
The platform centralizes logs across services, reduces mean time to resolution through actionable dashboards and alerts, and establishes a foundation for broader observability. Automation minimizes manual steps and configuration drift.

\chapter{Project Management}
\section{Organization and Roles}
The project was executed by the intern (Idris SADDI) under the supervision of Salma SEDDIK. Stakeholders included SRE and backend teams. Weekly checkpoints ensured alignment with objectives and timely risk handling.

\section{Schedule Tracking}
The Gantt plan was updated as tasks progressed. Buffer periods were reserved for stabilization and tuning. Changes were documented in commit messages and issue threads.

\section{Communication}
Stand-ups and async updates (issue comments, pull request notes) maintained transparency. Decisions were captured near the code (README and scripts) for future maintainers.

\chapter{Budget and Resource Estimate}
\begin{table}[H]
\centering
\begin{tabular}{p{5cm} p{4cm} p{6cm}}
\toprule
\textbf{Item} & \textbf{Cost (indicative)} & \textbf{Notes} \\
\midrule
Compute (containers) & Internal & Developer workstation resources for local runs \\
Storage (OpenSearch) & Internal & Depends on retention and volume; see capacity planning \\
Time (engineering) & Internship duration & Design, implementation, validation, documentation \\
\bottomrule
\end{tabular}
\caption{Budget/resource estimation for prototype environment}
\end{table}

\chapter{Knowledge Transfer and Maintainability}
\section{Documentation}
The repository README details architecture, setup, testing, and troubleshooting. Scripts include inline documentation and self-checks. The reportâ€™s appendices embed exact source files for traceability.

\section{Handover}
Handover sessions cover environment bootstrap, Graylog automation flows, and dashboard customization. Future contributors can extend services and alert definitions following established patterns.

\chapter{Evaluation and Academic Criteria}
This work demonstrates: problem framing (observability challenges), method (iterative delivery), engineering rigor (automation, testing), and reflection (risks, ethics, and future work). The deliverable meets academic expectations for completeness, reproducibility, and clarity.

\chapter*{General Conclusion}
\addcontentsline{toc}{chapter}{General Conclusion}
This internship consolidated my skills in distributed architectures, messaging, observability, and containerized deployments while addressing real-world challenges for the Siratify entrepreneurial ecosystem platform. The delivered centralized log management solution provides a robust, industrializable foundation for monitoring Siratify's microservices that facilitate connections between entrepreneurs, investors, mentors, and support organizations.

The implementation demonstrates how modern logging architecture can enhance platform reliability and user experience in multi-stakeholder environments. Future enhancements for Siratify include advanced correlation for user journey tracking, distributed tracing integration (OpenTelemetry), SSO integration for Graylog access control, and richer alert routing for business-critical platform events.

\chapter*{Future Work}
\addcontentsline{toc}{chapter}{Future Work}
Planned improvements: secure-by-default TLS across services, CI/CD integration for infrastructure changes, automated capacity planning for OpenSearch, and multi-environment (dev/stage/prod) configuration overlays.

\appendix
\chapter{docker-compose.yml}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../docker-compose.yml}

\chapter{graylog-init.sh}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../graylog-init.sh}

\chapter{service1 LogController.java}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service1/src/main/java/com/idris/service1/LogController.java}

\chapter{log-service LogConsumer.java}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../log-service/src/main/java/com/idris/log_service/kafka/LogConsumer.java}

\chapter{logback-spring.xml (log-service)}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../log-service/src/main/resources/logback-spring.xml}

\chapter{service1 application.properties}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service1/src/main/resources/application.properties}

\chapter{service2 application.properties}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service2/src/main/resources/application.properties}

\chapter{service2 logback-spring.xml}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service2/src/main/resources/logback-spring.xml}

\chapter{log-service application.properties}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../log-service/src/main/resources/application.properties}

\chapter{service1 logback-spring.xml}
\VerbatimInput[frame=single, fontsize=\scriptsize, xleftmargin=0.5cm, xrightmargin=0.5cm]{../service1/src/main/resources/logback-spring.xml}

\end{document}
